<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Live Transcription POC</title>
  <style>
    * { box-sizing: border-box; margin: 0; padding: 0; }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%);
      min-height: 100vh;
      color: white;
      padding: 20px;
    }
    .container { max-width: 1200px; margin: 0 auto; }
    h1 { text-align: center; font-size: 1.8rem; margin-bottom: 10px; background: linear-gradient(90deg, #a855f7, #ec4899); -webkit-background-clip: text; -webkit-text-fill-color: transparent; }
    .subtitle { text-align: center; color: #888; margin-bottom: 20px; }
    .controls { display: flex; justify-content: center; gap: 15px; margin-bottom: 30px; }
    .mic-btn { width: 100px; height: 100px; border-radius: 50%; border: none; cursor: pointer; font-size: 2.5rem; transition: all 0.3s; }
    .mic-btn.idle { background: linear-gradient(135deg, #22c55e, #16a34a); }
    .mic-btn.listening { background: linear-gradient(135deg, #ef4444, #dc2626); animation: pulse 1s infinite; }
    .mic-btn:hover { transform: scale(1.05); }
    @keyframes pulse { 0%, 100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.4); } 50% { box-shadow: 0 0 0 20px rgba(239, 68, 68, 0); } }
    .status { text-align: center; padding: 10px; border-radius: 8px; margin-bottom: 20px; }
    .status.idle { background: rgba(100,100,100,0.3); }
    .status.connecting { background: rgba(234,179,8,0.3); color: #fbbf24; }
    .status.listening { background: rgba(34,197,94,0.3); color: #4ade80; }
    .status.error { background: rgba(239,68,68,0.3); color: #f87171; }
    .audio-level { height: 8px; background: rgba(255,255,255,0.1); border-radius: 4px; margin-bottom: 20px; overflow: hidden; }
    .audio-level-bar { height: 100%; background: linear-gradient(90deg, #22c55e, #fbbf24, #ef4444); transition: width 0.1s; }
    .languages { display: flex; flex-direction: column; gap: 8px; }
    .lang-card { background: rgba(255,255,255,0.05); border-radius: 8px; overflow: hidden; border: 1px solid rgba(255,255,255,0.1); transition: all 0.3s; display: flex; align-items: stretch; }
    .lang-card.active { border-color: #a855f7; box-shadow: 0 0 15px rgba(168,85,247,0.3); }
    .lang-header { padding: 12px 16px; background: rgba(0,0,0,0.3); display: flex; align-items: center; gap: 8px; font-weight: 600; min-width: 140px; flex-shrink: 0; }
    .lang-header .flag { font-size: 1.3rem; }
    .lang-header .indicator { width: 8px; height: 8px; border-radius: 50%; background: #22c55e; margin-left: auto; display: none; }
    .lang-card.active .indicator { display: block; animation: pulse 1s infinite; }
    .lang-content { padding: 12px 16px; flex: 1; min-height: 50px; max-height: 120px; overflow-y: auto; display: flex; flex-wrap: wrap; align-items: center; gap: 8px; }
    .transcript-line { padding: 6px 10px; background: rgba(255,255,255,0.08); border-radius: 6px; border-left: 3px solid #a855f7; animation: fadeIn 0.3s; font-size: 0.95rem; }
    .transcript-line.interim { opacity: 0.6; border-left-color: #888; font-style: italic; }
    .transcript-line .time { display: none; }
    @keyframes fadeIn { from { opacity: 0; transform: translateY(10px); } to { opacity: 1; transform: translateY(0); } }
    .empty-state { color: #555; font-style: italic; font-size: 0.9rem; }
    .footer { text-align: center; margin-top: 30px; color: #666; font-size: 0.8rem; }
    .debug { background: rgba(0,0,0,0.5); padding: 10px; border-radius: 8px; margin-bottom: 20px; font-family: monospace; font-size: 12px; max-height: 100px; overflow-y: auto; }
  </style>
</head>
<body>
  <div class="container">
    <h1>üéôÔ∏è Live Transcription POC</h1>
    <p class="subtitle">Speak in English, Spanish, Chinese, or French</p>
    <div class="controls">
      <button class="mic-btn idle" id="micBtn" onclick="toggleCapture()">üé§</button>
    </div>
    <div class="status idle" id="status">Tap the microphone to start</div>
    <div class="debug" id="debug">Ready...</div>
    <div class="audio-level"><div class="audio-level-bar" id="audioLevel" style="width: 0%"></div></div>
    <div class="languages">
      <div class="lang-card" id="card-en"><div class="lang-header"><span class="flag">üá∫üá∏</span><span>English</span><span class="indicator"></span></div><div class="lang-content" id="content-en"><div class="empty-state">Waiting...</div></div></div>
      <div class="lang-card" id="card-es"><div class="lang-header"><span class="flag">üá™üá∏</span><span>Espa√±ol</span><span class="indicator"></span></div><div class="lang-content" id="content-es"><div class="empty-state">Esperando...</div></div></div>
      <div class="lang-card" id="card-zh"><div class="lang-header"><span class="flag">üá®üá≥</span><span>‰∏≠Êñá</span><span class="indicator"></span></div><div class="lang-content" id="content-zh"><div class="empty-state">Á≠âÂæÖ...</div></div></div>
      <div class="lang-card" id="card-fr"><div class="lang-header"><span class="flag">üá´üá∑</span><span>Fran√ßais</span><span class="indicator"></span></div><div class="lang-content" id="content-fr"><div class="empty-state">En attente...</div></div></div>
    </div>
    <div class="footer">CASEC 2026 Spring Gala ‚Ä¢ Live Transcription POC</div>
  </div>
<script>
let isCapturing = false, socket = null, stream = null, audioContext = null, analyser = null, processor = null;
const langMap = {'en':'en','en-US':'en','es':'es','es-ES':'es','zh':'zh','zh-CN':'zh','cmn':'zh','fr':'fr','fr-FR':'fr'};
const langNames = {'en':'English','es':'Spanish','zh':'Chinese','fr':'French'};

function log(msg) { 
  console.log(msg); 
  const d = document.getElementById('debug');
  d.textContent = new Date().toLocaleTimeString() + ' ' + msg + '\n' + d.textContent.split('\n').slice(0,5).join('\n');
}

function setStatus(type, msg) { const el = document.getElementById('status'); el.className = 'status ' + type; el.textContent = msg; }
function setActive(lang) { document.querySelectorAll('.lang-card').forEach(c => c.classList.remove('active')); document.getElementById('card-' + lang)?.classList.add('active'); }

function addLine(lang, text, final) {
  const c = document.getElementById('content-' + lang); if (!c) return;
  c.querySelector('.empty-state')?.remove();
  c.querySelector('.interim')?.remove();
  const div = document.createElement('div');
  div.className = 'transcript-line' + (final ? '' : ' interim');
  div.innerHTML = '<div>' + text + '</div>' + (final ? '<div class="time">' + new Date().toLocaleTimeString() + '</div>' : '');
  c.appendChild(div);
  c.scrollTop = c.scrollHeight;
}

async function translate(text, from, to) {
  if (from === to || !text.trim()) return text;
  try {
    log('Translating to ' + langNames[to] + ': ' + text.substring(0, 30) + '...');
    const r = await fetch('https://synthia.bot/api/chat/message', {
      method: 'POST', headers: {'Content-Type': 'application/json'},
      body: JSON.stringify({message: 'Translate to ' + langNames[to] + '. Reply with ONLY the translation, nothing else: ' + text, sessionId: 'translate-' + to})
    });
    if (!r.ok) { log('Translate HTTP error: ' + r.status); return text; }
    const d = await r.json();
    log('Translation response: ' + JSON.stringify(d).substring(0, 100));
    const result = d.response || d.message || d.reply || text;
    return result.replace(/^["']|["']$/g, '').trim();
  } catch(e) { log('Translate error: ' + e); return text; }
}

async function handleText(text, lang, final) {
  if (!text || !text.trim()) return;
  
  // Show transcript in detected language box
  addLine(lang, text, final);
  setActive(lang);
  
  // Only translate final results
  if (!final) return;
  
  log('Final transcript (' + lang + '): ' + text);
  
  // Translate to other 3 languages using the new translate endpoint
  try {
    const r = await fetch('/api/chat/translate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text, sourceLanguage: lang })
    });
    if (!r.ok) {
      log('Translate HTTP error: ' + r.status);
      return;
    }
    const d = await r.json();
    log('Translations: ' + JSON.stringify(d).substring(0, 200));
    
    // Add translations to other language boxes
    const translations = d.translations || {};
    for (const [toLang, translated] of Object.entries(translations)) {
      if (toLang !== lang && translated && translated.trim()) {
        addLine(toLang, translated, true);
      }
    }
  } catch(e) {
    log('Translation error: ' + e);
  }
}

function monitorAudio() {
  if (!analyser) return;
  const data = new Uint8Array(analyser.frequencyBinCount);
  (function update() {
    if (!analyser || !isCapturing) return;
    analyser.getByteFrequencyData(data);
    document.getElementById('audioLevel').style.width = (data.reduce((a,b)=>a+b)/data.length/255*100) + '%';
    requestAnimationFrame(update);
  })();
}

// Convert Float32Array to Int16Array (linear16)
function floatTo16BitPCM(float32Array) {
  const int16 = new Int16Array(float32Array.length);
  for (let i = 0; i < float32Array.length; i++) {
    const s = Math.max(-1, Math.min(1, float32Array[i]));
    int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }
  return int16;
}

async function toggleCapture() { isCapturing ? stopCapture() : await startCapture(); }

async function startCapture() {
  try {
    log('Requesting mic...');
    setStatus('connecting', 'Requesting microphone...');
    stream = await navigator.mediaDevices.getUserMedia({audio: {channelCount: 1, sampleRate: 16000, echoCancellation: true, noiseSuppression: true}});
    log('Mic granted');
    
    audioContext = new (window.AudioContext || window.webkitAudioContext)({sampleRate: 16000});
    const source = audioContext.createMediaStreamSource(stream);
    
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);
    
    // Use ScriptProcessorNode to get raw PCM data
    processor = audioContext.createScriptProcessor(4096, 1, 1);
    source.connect(processor);
    processor.connect(audioContext.destination);
    
    log('Connecting to Deepgram...');
    setStatus('connecting', 'Connecting to Deepgram...');
    
    // Nova-3 has native multilingual support with code-switching
    const params = new URLSearchParams({
      model: 'nova-3',
      language: 'multi',
      encoding: 'linear16',
      sample_rate: '16000',
      channels: '1',
      punctuate: 'true',
      interim_results: 'true',
      smart_format: 'true'
    });
    
    const proxyUrl = `wss://gw.synthia.bot/dgproxy?${params}`;
    log('Connecting to: ' + proxyUrl);
    socket = new WebSocket(proxyUrl);
    
    socket.binaryType = 'arraybuffer';
    
    socket.onopen = () => {
      log('‚úì Connected!');
      setStatus('listening', 'üî¥ Listening... Speak now!');
      isCapturing = true;
      document.getElementById('micBtn').className = 'mic-btn listening';
      document.getElementById('micBtn').textContent = '‚èπÔ∏è';
      monitorAudio();
      
      // Send raw PCM audio
      processor.onaudioprocess = (e) => {
        if (socket?.readyState === 1) {
          const inputData = e.inputBuffer.getChannelData(0);
          const pcmData = floatTo16BitPCM(inputData);
          socket.send(pcmData.buffer);
        }
      };
      log('Recording started');
    };
    
    socket.onmessage = e => {
      try {
        const text = e.data instanceof ArrayBuffer 
          ? new TextDecoder().decode(e.data) 
          : e.data;
        const d = JSON.parse(text);
        log('DG: ' + JSON.stringify(d).substring(0, 150));
        const alt = d.channel?.alternatives?.[0];
        const t = alt?.transcript;
        if (!t) return;
        // Nova-2 multilingual returns language in alternatives[0].languages[0]
        const detectedLang = alt?.languages?.[0] || d.channel?.detected_language || 'en';
        const lang = langMap[detectedLang] || langMap[detectedLang.split('-')[0]] || 'en';
        log('Detected lang: ' + detectedLang + ' -> ' + lang);
        handleText(t, lang, d.is_final);
      } catch(err) { log('Parse err: ' + err); }
    };
    
    socket.onerror = e => { log('WS error'); setStatus('error', 'Connection error'); stopCapture(); };
    socket.onclose = e => { log('WS closed: ' + e.code + ' ' + (e.reason||'')); if(isCapturing) { setStatus('error', 'Disconnected: ' + e.code); stopCapture(); }};
    
  } catch(err) { log('Error: ' + err.message); setStatus('error', err.message); stopCapture(); }
}

function stopCapture() {
  isCapturing = false;
  if (processor) { processor.disconnect(); processor = null; }
  socket?.close(); socket = null;
  stream?.getTracks().forEach(t => t.stop()); stream = null;
  audioContext?.close(); audioContext = null; analyser = null;
  document.getElementById('audioLevel').style.width = '0%';
  document.getElementById('micBtn').className = 'mic-btn idle';
  document.getElementById('micBtn').textContent = 'üé§';
  log('Stopped');
}
</script>
</body>
</html>
